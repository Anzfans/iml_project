{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c102e5",
   "metadata": {},
   "source": [
    "## XGboost\n",
    "\n",
    "在处理XGboost的输入数据的时候，我们再对于特征进行了的一步处理，对于所有的类别特征，我们首先关于每个特征都做了一个，认购率和特征内类别的分析，然后按照后续方法实现特征工程\n",
    "\n",
    "# 实验记录：基于平滑目标编码（Target Encoding）与特征增强的 XGBoost 优化\n",
    "\n",
    "## 1. 实验背景与问题分析\n",
    "在之前的版本中，XGBoost 的准确率低于 Logistic Regression。经分析，主要原因如下：\n",
    "* **编码随机性**：原先使用的 `pd.factorize` 产生的整数（0, 1, 2...）对树模型而言没有逻辑意义，无法体现职业、月份等特征与购买率的直接关联。\n",
    "\n",
    "## 2. 核心改进方法：平滑目标编码 (Smoothed Target Encoding)\n",
    "我们将类别特征替换为该类别对应的**平滑转化率**。\n",
    "* **计算公式**：\n",
    "    $$Encoding = \\frac{(count_{category} \\cdot mean_{category}) + (m \\cdot mean_{global})}{count_{category} + m}$$\n",
    "* **平滑系数 ($m=50$)**：当类别样本量较小时，编码值会向全局均值靠拢，有效防止过拟合。\n",
    "\n",
    "## 3. 实验代码实现\n",
    "\n",
    "### 3.1 定义映射学习函数\n",
    "```python\n",
    "def get_target_mapping(train_df, cols):\n",
    "    \"\"\"从训练集中学习平滑后的目标映射\"\"\"\n",
    "    mapping = {}\n",
    "    # 确保 target 列已转换为数值 0/1\n",
    "    global_mean = train_df['subscribe'].map({'yes': 1, 'no': 0}).mean() \n",
    "    m = 50  # 平滑系数，可调参\n",
    "    \n",
    "    # 临时计算列用于统计\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['target_num'] = train_df['subscribe'].map({'yes': 1, 'no': 0})\n",
    "    \n",
    "    for col in cols:\n",
    "        stats = temp_df.groupby(col)['target_num'].agg(['count', 'mean'])\n",
    "        # 应用平滑公式\n",
    "        smooth = (stats['count'] * stats['mean'] + m * global_mean) / (stats['count'] + m)\n",
    "        mapping[col] = smooth.to_dict()\n",
    "        \n",
    "    mapping['_global_mean'] = global_mean\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945738e",
   "metadata": {},
   "source": [
    "## 在此方法下，准确率可以到达96.3"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
